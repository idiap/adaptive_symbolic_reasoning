{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework Demo: Single Question Solving\n",
    "\n",
    "\n",
    "\n",
    "## üìñ Overview\n",
    "\n",
    "\n",
    "\n",
    "This notebook demonstrates the **Adaptive LLM-Symbolic Reasoning Framework** solving a TREC clinical trial matching problem.\n",
    "\n",
    "\n",
    "\n",
    "### Framework Capabilities\n",
    "\n",
    "\n",
    "\n",
    "- **Automatic Problem Type Identification:** Detects reasoning problem type (SAT, CSP, FOL, LP, etc.)\n",
    "\n",
    "- **Dynamic Solver Selection:** Chooses appropriate solver based on problem type\n",
    "\n",
    "- **Hybrid Reasoning:** Combines LLM analysis with formal symbolic solvers\n",
    "\n",
    "- **Dual Model Support:** Works with Azure OpenAI (gpt-4o, gemini, ...) or local models (Qwen2.5-Coder-7B, ...)\n",
    "\n",
    "\n",
    "\n",
    "### Available Solvers\n",
    "\n",
    "\n",
    "\n",
    "| Solver | Problem Type |\n",
    "|--------|--------------|\n",
    "| SMT | Satisfiability Modulo Theories |\n",
    "| LP | Logic Programming |\n",
    "| FOL | First-order Logics |\n",
    "| CSP | Constraint Satisfaction Problems |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**‚ö†Ô∏è Prerequisites:** Configure `config.yaml` with API keys and model settings before running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Workflow\n",
    "<img src=\"./main_pic_single.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Problem Sample\n",
    "\n",
    "Load a clinical trial matching problem from the TREC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample ID: SMT_0\n",
      "Problem Type: Analytic Reasoning\n",
      "\n",
      "Problem Description:\n",
      "You get a trial and a patient and have to say if there is a match:\n",
      "\n",
      "TRIAL: Inclusion Criteria:\n",
      "\n",
      "* Adult patients (age \\>18 years) with acute pancreatitis according to the revised Atlanta criteria;12\n",
      "* Informed consent;\n",
      "* Known time of debut of symptoms.\n",
      "\n",
      "Exclusion Criteria:\n",
      "\n",
      "* Chronic pancreatitis;\n",
      "* Pregnancy;\n",
      "* Known malignant disease;\n",
      "* More than 72 hours from debut of symptoms to inclusion.\n",
      "\n",
      "PATIENT: The patient is a 57-year-old man with abdominal pain and vomiting. The pain started gradually about 20 hours ago in the epigastric and periumbilical regions, radiating to his back. He drinks around 60 units of alcohol per week and smokes 22 cigarettes per day. He is healthy with no history of allergies or using any medications. His family history is positive for type 2 diabetes (his father and sister). He lives alone and has no children. The abdomen is tender and soft. His bowel sounds are normal. His heart rate is 115/min and blood pressure 110/75 mmHg. The lab results are remarkable for leukocytosis (19.5), urea of 8.5, high CRP (145), high amylase (1200) and Glc level of 15. Cross-sectional imaging was negative for obstructive pancreatitis.\n",
      "\n",
      "Does the patient match the trial?\n",
      "A) True\n",
      "B) False\n",
      "\n",
      "Ground Truth Answer: A\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load configuration\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Load a sample from TREC dataset\n",
    "data_path = config['data_dir']['trec']\n",
    "with open(data_path, 'r') as f:\n",
    "    trec_data = json.load(f)\n",
    "\n",
    "# Select the first sample (you can modify the index to try other samples)\n",
    "sample = trec_data[0]\n",
    "if not isinstance(sample['answer'], list):\n",
    "    sample['answer'] = [sample['answer']]\n",
    "\n",
    "print(f\"Sample ID: {sample['id']}\")\n",
    "print(f\"Problem Type: {sample['type']}\")\n",
    "print(f\"\\nProblem Description:\")\n",
    "print(sample['problem'])\n",
    "print(f\"\\nGround Truth Answer: {sample['answer'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Option A: Reasoning with Azure OpenAI (gpt-4o)\n",
    "\n",
    "This section demonstrates using Azure OpenAI API for reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: Configure LLM\n",
    "\n",
    "Initialize the Azure OpenAI client with credentials from `config.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Azure OpenAI (gpt-4o) initialized successfully\n"
     ]
    }
   ],
   "source": [
    "from agents.generation.api import AzureOpenAIGenerator\n",
    "\n",
    "# Initialize Azure OpenAI (using gpt-4o-azure config from config.yaml)\n",
    "azure_config = config['api_config']['gpt-4o-azure']\n",
    "llm = AzureOpenAIGenerator(\n",
    "    model_name=azure_config['model_name'],\n",
    "    api_key=azure_config['api_key'],\n",
    "    model_version=azure_config['openai_api_version'],\n",
    "    azure_endpoint=azure_config['azure_endpoint']\n",
    ")\n",
    "\n",
    "print(\"‚úì Azure OpenAI (gpt-4o) initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: Create Reasoning Plan\n",
    "\n",
    "The **router** analyzes the problem and creates an execution plan:\n",
    "- Identifies the problem type (e.g., SAT, CSP, FOL)\n",
    "- Selects appropriate solver(s) from the portfolio\n",
    "- Constructs a DAG (Directed Acyclic Graph) showing the execution workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 19:54:32,460 | INFO | Registered agent '<PLAN_START>'\n",
      "2025-10-27 19:54:32,461 | INFO | Registered agent '<PLAN_END>'\n",
      "2025-10-27 19:54:32,462 | INFO | Registered agent 'lp_solver'\n",
      "2025-10-27 19:54:32,462 | INFO | Registered agent 'fol_solver'\n",
      "2025-10-27 19:54:32,463 | INFO | Registered agent 'csp_solver'\n",
      "2025-10-27 19:54:32,463 | INFO | Registered agent 'smt_solver'\n",
      "2025-10-27 19:54:32,464 | INFO | Registered agent 'ilp_solver'\n",
      "2025-10-27 19:54:32,464 | INFO | Registered agent 'epistemic_solver'\n",
      "2025-10-27 19:54:32,464 | INFO | Registered agent 'risk_solver'\n",
      "2025-10-27 19:54:32,465 | INFO | Registered agent 'compositional_solver'\n",
      "2025-10-27 19:54:32,465 | INFO | Registered agent 'causal_solver'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Carnap router initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 19:54:35,156 | INFO | HTTP Request: POST https://lunarchatgpt.openai.azure.com/openai/deployments/lunar-chatgpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 19:54:35,161 | INFO | Scratchpad WRITE problem_type_ques_1=SAT (ttl=None)\n",
      "2025-10-27 19:54:35,161 | INFO | Scratchpad WRITE trial_description_ques_1=Inclusion Criteria:\n",
      "\n",
      "* Adult patients (age >18 years) with a (ttl=None)\n",
      "2025-10-27 19:54:35,162 | INFO | Scratchpad WRITE sample_description_ques_1=The patient is a 57-year-old man with abdominal pain and vom (ttl=None)\n",
      "2025-10-27 19:54:35,162 | INFO | Scratchpad WRITE options_ques_1=A) True\n",
      "B) False (ttl=None)\n",
      "2025-10-27 19:54:35,162 | INFO | Scratchpad WRITE smt_input_ques_1={'problem': 'Trial: Inclusion Criteria:\\n\\n* Adult patients  (ttl=None)\n",
      "2025-10-27 19:54:35,163 | INFO | Scratchpad WRITE description_ques_1=For a Boolean Satisfiability (SAT) problem, verify whether a (ttl=None)\n",
      "2025-10-27 19:54:35,163 | INFO | Scratchpad WRITE GOAL=Solve the reasoning problem (ttl=None)\n",
      "2025-10-27 19:54:35,163 | INFO | Scratchpad WRITE parsing_result=[{'problem_id': 'ques_1', 'problem_type': 'SAT', 'trial_desc (ttl=None)\n",
      "2025-10-27 19:54:35,164 | INFO | Scratchpad WRITE portfolio={'<PLAN_START>': {'goal': 'Special control marker, indicatin (ttl=None)\n",
      "2025-10-27 19:54:35,822 | INFO | HTTP Request: POST https://lunarchatgpt.openai.azure.com/openai/deployments/lunar-chatgpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 19:54:35,824 | INFO | [planner] produced plan spec: {'agents': ['ques_1', 'smt_solver', '<PLAN_END>'], 'edges': [['ques_1', 'smt_solver'], ['smt_solver', '<PLAN_END>']]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Plan created successfully\n",
      "\n",
      "Identified problem type(s): ['SAT']\n",
      "Agents in plan: ['<PLAN_START>', 'ques_1', 'smt_solver', '<PLAN_END>']\n"
     ]
    }
   ],
   "source": [
    "from agents.meta_agents.planner import Planner\n",
    "\n",
    "# Initialize Carnap router with the LLM\n",
    "router = Planner(generator=llm)\n",
    "print(\"‚úì Carnap router initialized\")\n",
    "\n",
    "# Router creates execution plan by analyzing the problem\n",
    "plan, memory, problem_ids = router(sample)\n",
    "plan = plan[0]\n",
    "\n",
    "print(\"‚úì Plan created successfully\")\n",
    "print(f\"\\nIdentified problem type(s): {[memory.read(f'problem_type_{pid}') for pid in problem_ids]}\")\n",
    "print(f\"Agents in plan: {list(plan.agents.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3: Execute Plan and Show Intermediate Results\n",
    "\n",
    "\n",
    "\n",
    "Execute the reasoning plan using the selected solvers.\n",
    "\n",
    "\n",
    "\n",
    "**Plan Structure (DAG)** shows the execution flow:\n",
    "\n",
    "- `<PLAN_START> ‚Üí ques_1`: Problem enters the pipeline\n",
    "\n",
    "- `ques_1 ‚Üí solver`: Question is passed to the appropriate solver (e.g., smt_solver)\n",
    "\n",
    "- `solver ‚Üí <PLAN_END>`: Results flow to completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 19:54:47,171 | INFO | Execute plan with topological order...\n",
      "2025-10-27 19:54:47,172 | INFO | Trace saved: <PLAN_START> ‚Üí None\n",
      "2025-10-27 19:54:47,172 | INFO | Trace saved: ques_1 ‚Üí None\n",
      "2025-10-27 19:54:47,173 | INFO | Scratchpad WRITE smt_problem_queue_smt_solver=[] (ttl=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing reasoning plan...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 19:54:51,320 | INFO | HTTP Request: POST https://lunarchatgpt.openai.azure.com/openai/deployments/lunar-chatgpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 19:54:51,322 | INFO | Attempt 1/1\n",
      "2025-10-27 19:54:51,323 | INFO | Running Z3 command: z3 -smt2 /tmp/tmp_p2gjszn.smt2\n",
      "2025-10-27 19:54:51,337 | INFO | Z3 ran successfully. Found 1 solutions\n",
      "2025-10-27 19:54:51,337 | INFO | Scratchpad WRITE smt_results_queue=[{'ori_answer': {}, 'parsed_answer': 'A', 'success': True, ' (ttl=None)\n",
      "2025-10-27 19:54:51,338 | INFO | Scratchpad WRITE result_ques_1={'ori_answer': {}, 'parsed_answer': 'A', 'success': True, 'e (ttl=None)\n",
      "2025-10-27 19:54:51,338 | INFO | Trace saved: smt_solver ‚Üí {'ori_answer': {}, 'parsed_answer': 'A', 'success': True, 'error': None, 'is_satisfiable': 'A', 'code': '; Declare variables and their types\\n(declare-const age Int)\\n(declare-const has_acute_pancreatitis Bool)\\n(declare-const informed_consent Bool)\\n(declare-const known_time_of_symptom_debut Bool)\\n(declare-const has_chronic_pancreatitis Bool)\\n(declare-const is_pregnant Bool)\\n(declare-const has_malignant_disease Bool)\\n(declare-const hours_since_symptom_debut Int)\\n\\n; Assert inclusion criteria\\n(assert (and\\n  (> age 18)\\n  has_acute_pancreatitis\\n  informed_consent\\n  known_time_of_symptom_debut\\n))\\n\\n; Assert exclusion criteria\\n(assert (not (or\\n  has_chronic_pancreatitis\\n  is_pregnant\\n  has_malignant_disease\\n  (> hours_since_symptom_debut 72)\\n)))\\n\\n; Sample patient information\\n(assert (= age 57))\\n(assert (= has_acute_pancreatitis true))\\n(assert (= informed_consent true))\\n(assert (= known_time_of_symptom_debut true))\\n(assert (= has_chronic_pancreatitis false))\\n(assert (= is_pregnant false))\\n(assert (= has_malignant_disease false))\\n(assert (= hours_since_symptom_debut 20))\\n(check-sat)'}\n",
      "2025-10-27 19:54:51,338 | INFO | Trace saved: <PLAN_END> ‚Üí None\n",
      "2025-10-27 19:54:51,339 | INFO | Topological execution complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Reasoning completed\n",
      "\n",
      "Plan Structure (DAG):\n",
      "  <PLAN_START> -> ques_1\n",
      "  ques_1 -> smt_solver\n",
      "  smt_solver -> <PLAN_END>\n"
     ]
    }
   ],
   "source": [
    "from agents.meta_agents.planner import TracePersister\n",
    "\n",
    "# Execute the reasoning plan\n",
    "print(\"Executing reasoning plan...\\n\")\n",
    "plan.execute(memory, TracePersister())\n",
    "print(\"\\n‚úì Reasoning completed\")\n",
    "\n",
    "# Display plan structure (DAG)\n",
    "print(\"\\nPlan Structure (DAG):\")\n",
    "for edge in plan.edges:\n",
    "    print(f\"  {edge.source} -> {edge.target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 4: Extract and Evaluate Results\n",
    "\n",
    "\n",
    "\n",
    "Extract predictions from the reasoning process and compare with ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Result Comparison\n",
      "============================================================\n",
      "Ground Truth: ['A']\n",
      "Prediction:   ['A']\n",
      "\n",
      "Evaluation: ‚úÖ Correct\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Extract results from memory\n",
    "predictions = []\n",
    "for pid in problem_ids:\n",
    "    result = memory.read(f\"result_{pid}\") or memory.read(f\"result_no_problem\") or {}\n",
    "    predictions.append(result.get('parsed_answer', None))\n",
    "\n",
    "# Evaluate results\n",
    "is_correct = all(pred == gt for pred, gt in zip(predictions, sample['answer']))\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 60)\n",
    "print(\"Result Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Ground Truth: {sample['answer']}\")\n",
    "print(f\"Prediction:   {predictions}\")\n",
    "print(f\"\\nEvaluation: {'‚úÖ Correct' if is_correct else '‚ùå Incorrect'}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Option B: Reasoning with Local Model (Qwen2.5-Coder-7B)\n",
    "\n",
    "This section uses a **local open-source model** (Qwen2.5-Coder-7B-Instruct) instead of Azure OpenAI.\n",
    "\n",
    "### Key Difference: LLM Initialization\n",
    "\n",
    "The main difference from Option A is how we initialize the LLM:\n",
    "- **Option A:** Uses `AzureOpenAIGenerator` to connect to Azure OpenAI API\n",
    "- **Option B:** Uses `LocalGenerator` to load a local model with transformers\n",
    "\n",
    "All other steps (routing, plan creation, execution, result extraction) follow the same process as Option A.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** First run includes model loading time. GPU acceleration recommended for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.generation.local import LocalGenerator\n",
    "from agents.meta_agents.planner import TracePersister, Planner\n",
    "\n",
    "# Initialize local model (using qwen2.5-coder-7b config from config.yaml)\n",
    "local_config = config['api_config']['qwen2.5-coder-7b']\n",
    "llm_local = LocalGenerator(\n",
    "    model_name=local_config['model_name'],\n",
    "    api_key=local_config['api_key'],\n",
    "    lora_path=local_config.get('lora_path', None)\n",
    ")\n",
    "\n",
    "# Initialize Carnap router\n",
    "router_local = Planner(generator=llm_local)\n",
    "print(\"‚úì Carnap router initialized with Local Model (qwen2.5-coder-7b)\")\n",
    "\n",
    "# Router creates execution plan\n",
    "plan_local, memory_local, problem_ids_local = router_local(sample)\n",
    "plan_local = plan_local[0]\n",
    "\n",
    "# Execute reasoning plan\n",
    "print(\"\\nExecuting reasoning...\")\n",
    "plan_local.execute(memory_local, TracePersister())\n",
    "\n",
    "# Extract results\n",
    "predictions_local = []\n",
    "for pid in problem_ids_local:\n",
    "    result = memory_local.read(f\"result_{pid}\") or memory_local.read(f\"result_no_problem\") or {}\n",
    "    predictions_local.append(result.get('parsed_answer', None))\n",
    "\n",
    "print(\"‚úì Reasoning completed\")\n",
    "\n",
    "# Evaluate results\n",
    "is_correct_local = all(pred == gt for pred, gt in zip(predictions_local, sample['answer']))\n",
    "\n",
    "# Get predicted problem types\n",
    "problem_types_local = [memory_local.read(f'problem_type_{pid}') for pid in problem_ids_local]\n",
    "print(f\"\\nPredicted problem type(s): {problem_types_local}\")\n",
    "print(f\"Agents used: {list(plan_local.agents.keys())}\")\n",
    "\n",
    "# Display plan structure\n",
    "print(f\"\\nPlan Structure (DAG):\")\n",
    "for edge in plan_local.edges:\n",
    "    print(f\"  {edge.source} -> {edge.target}\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Result Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Ground Truth: {sample['answer']}\")\n",
    "print(f\"Prediction:   {predictions_local}\")\n",
    "print(f\"\\nEvaluation: {'‚úÖ Correct' if is_correct_local else '‚ùå Incorrect'}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carnap_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

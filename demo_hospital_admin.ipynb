{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üè• Adaptive Reasoning for Healthcare Administration\n",
        "\n",
        "## Real-World Multi-Task Reasoning with Symbolic AI\n",
        "\n",
        "This demo showcases an **adaptive LLM-symbolic reasoning framework** solving realistic healthcare administration tasks, automatically routing each problem to the optimal solver.\n",
        "\n",
        "---\n",
        "\n",
        "### üìã Scenario: Hospital Admin Assistant\n",
        "\n",
        "A hospital administrator faces three different reasoning tasks in a single workflow:\n",
        "\n",
        "<div style=\"display: grid; grid-template-columns: repeat(3, 1fr); gap: 15px; margin-top: 20px;\">\n",
        "\n",
        "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; color: white; box-shadow: 0 4px 6px rgba(0,0,0,0.1);\">\n",
        "<h4 style=\"margin-top: 0; color: white;\">üìä Task 1: Clinical Trial Matching</h4>\n",
        "<p style=\"font-size: 0.9em; margin-bottom: 5px;\"><strong>Type:</strong> Constraint Satisfaction</p>\n",
        "<p style=\"font-size: 0.85em; opacity: 0.95;\">Match patient profile against complex trial inclusion/exclusion criteria</p>\n",
        "<p style=\"font-size: 0.8em; margin-top: 10px; opacity: 0.9;\">‚öôÔ∏è Optimal solver: Z3 (SMT)</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); padding: 20px; border-radius: 10px; color: white; box-shadow: 0 4px 6px rgba(0,0,0,0.1);\">\n",
        "<h4 style=\"margin-top: 0; color: white;\">üîê Task 2: Policy Compliance</h4>\n",
        "<p style=\"font-size: 0.9em; margin-bottom: 5px;\"><strong>Type:</strong> First-Order Logic</p>\n",
        "<p style=\"font-size: 0.85em; opacity: 0.95;\">Verify staff credentialing against hospital policies</p>\n",
        "<p style=\"font-size: 0.8em; margin-top: 10px; opacity: 0.9;\">‚öôÔ∏è Optimal solver: Prover9</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); padding: 20px; border-radius: 10px; color: white; box-shadow: 0 4px 6px rgba(0,0,0,0.1);\">\n",
        "<h4 style=\"margin-top: 0; color: white;\">‚úÖ Task 3: Discharge Readiness</h4>\n",
        "<p style=\"font-size: 0.9em; margin-bottom: 5px;\"><strong>Type:</strong> Logic Programming</p>\n",
        "<p style=\"font-size: 0.85em; opacity: 0.95;\">Evaluate patient discharge eligibility via forward chaining</p>\n",
        "<p style=\"font-size: 0.8em; margin-top: 10px; opacity: 0.9;\">‚öôÔ∏è Optimal solver: Pyke</p>\n",
        "</div>\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Framework Capabilities\n",
        "\n",
        "‚ú® **Automatic Problem Detection** - Identifies reasoning type without manual specification  \n",
        "üß† **Heterogeneous Solver Selection** - Routes to optimal symbolic solver (Z3, Prover9, Pyke)  \n",
        "‚ö° **Parallel Execution** - Processes independent tasks concurrently  \n",
        "üîÑ **End-to-End Automation** - From natural language to verified answers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Hospital Admin Tasks\n",
        "\n",
        "Loading three realistic healthcare administration tasks that would typically be handled by different software systems.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "problem_description = '''\n",
        "PATIENT CASE FOR TRIAL MATCHING:\n",
        "Patient Profile:\n",
        "- 62-year-old male\n",
        "- History: CVA, neurogenic bladder with indwelling suprapubic catheter\n",
        "- Multiple prior admissions for UTIs, altered mental status, and urosepsis\n",
        "- Current: Urosepsis (now resolved after vanc/meropenem treatment)\n",
        "- CT findings: Non-obstructing stone in left ureter, no urethral strictures\n",
        "- Medical history: Non-Hodgkins Marginal Zone Lymphoma (s/p R-CHOP x6), Bell's Palsy, BPH, Hypertension, Partial bowel obstruction s/p colostomy, Hepatitis C, Cryoglobulinemia, SLE with transverse myelitis (anti-dsDNA Ab+), Insulin-dependent diabetes, Fungal esophagitis, Recurrent UTIs (Pseudomonas & Enterococcus)\n",
        "\n",
        "Clinical Trial: NCT02142751\n",
        "Trial Criteria:\n",
        "Inclusion:\n",
        "- ‚â•18 years old hospitalized patients\n",
        "- Negative pregnancy test in fertile women\n",
        "- Episode of monomicrobial urinary BSI due to multidrug-resistant E.coli (susceptible to fosfomycin and meropenem or ceftriaxone)\n",
        "- Urinary sepsis with MDR E.coli from blood cultures, requires:\n",
        "  Clinical criteria (at least one): UTI symptoms (dysuria, urgency, suprapubic pain, pollakiuria), lumbar back pain, costovertebral angle tenderness, altered mental status (‚â§70 years), intermittent/permanent indwelling Foley catheter\n",
        "  Urinalysis criteria (at least one): Positive dipstick for nitrites or leukocyte esterase, positive urine culture\n",
        "\n",
        "Exclusion criteria:\n",
        "- Polymicrobial bacteremia\n",
        "- Undrained renal abscess or unresolved obstructive uropathy\n",
        "- Pregnant or breastfeeding women\n",
        "- Hematogenous infection\n",
        "- Other concomitant infection\n",
        "- Renal transplant recipients\n",
        "- Polycystic kidney\n",
        "- Hypersensitivity to meropenem, fosfomycin, or ceftriaxone\n",
        "\n",
        "Based on the available information, can this patient be enrolled in the trial?\n",
        "A) Yes \n",
        "B) No\n",
        "\n",
        "\n",
        "HOSPITAL CREDENTIALING VERIFICATION:\n",
        "Excerpt from Hospital Policy Manual Section - Staff Credentialing Requirements:\n",
        "- All hospital staff members shall be classified as either clinical staff or administrative staff. \n",
        "- Clinical staff are defined as personnel who have direct patient contact in the course of their duties.\n",
        "- All clinical staff are required to complete annual infection control training as mandated by Joint Commission standards. \n",
        "- Upon successful completion of annual infection control training, staff members receive credentialing authorization. \n",
        "- Nurses are classified as clinical staff. Physicians are classified as clinical staff. \n",
        "- Billing clerks are classified as administrative staff. \n",
        "- Administrative staff do not have patient contact.\n",
        "\n",
        "Personnel Record for Johnson, R.N.:\n",
        "- Position: Registered Nurse\n",
        "- Annual Infection Control Training Status: Not Completed\n",
        "\n",
        "Question: According to hospital policy, is Nurse Johnson currently credentialed?\n",
        "A) Yes\n",
        "B) No\n",
        "\n",
        "\n",
        "DISCHARGE READINESS VERIFICATION:\n",
        "Patient Discharge Protocol - Standard Operating Procedure:\n",
        "- If a patient has stable vital signs, then the patient meets vital stability criteria. \n",
        "- If a patient is off IV antibiotics, then the patient meets antibiotic transition criteria. \n",
        "- If a patient meets vital stability criteria and meets antibiotic transition criteria, then the patient is medically stable. \n",
        "- If a patient can perform self-care activities, then the patient is functionally independent. \n",
        "- If a patient is functionally independent and has completed discharge teaching, then the patient meets discharge education requirements. \n",
        "- If a patient is medically stable and meets discharge education requirements, then the patient is cleared for discharge.\n",
        "\n",
        "Patient Status Report - Chen, Margaret (MRN: 445821):\n",
        "Margaret Chen has stable vital signs. Margaret Chen is off IV antibiotics. Margaret Chen can perform self-care activities. Margaret Chen has completed discharge teaching.\n",
        "\n",
        "Based on this discharge protocol, is Margaret Chen cleared for discharge?\n",
        "A) Yes\n",
        "B) No\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Devise Plan for Adaptive Reasoning \n",
        "\n",
        "The **Carnap Router** analyzes tasks and creates an execution plan.\n",
        "\n",
        "Let's first initialize load the config and initialize an LLM:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "from agents.generation.api import AzureOpenAIGenerator\n",
        "from agents.meta_agents.planner import Planner, TracePersister\n",
        "from helpers.trace_explainer import build_trace_payload, why\n",
        "# Load config and initialize\n",
        "with open('config.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)\n",
        "azure_config = config['api_config']['gpt-4o-azure']\n",
        "llm = AzureOpenAIGenerator(\n",
        "    model_name=azure_config['model_name'],\n",
        "    api_key=azure_config['api_key'],\n",
        "    model_version=azure_config['openai_api_version'],\n",
        "    azure_endpoint=azure_config['azure_endpoint']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, the router:\n",
        "\n",
        "- Parses the multi-task input\n",
        "- Classifies each task by reasoning type\n",
        "- Constructs an execution DAG\n",
        "- Routes tasks to appropriate symbolic solvers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-07 15:55:27,059 | INFO | Registered agent '<PLAN_START>'\n",
            "2025-11-07 15:55:27,060 | INFO | Registered agent '<PLAN_END>'\n",
            "2025-11-07 15:55:27,061 | INFO | Registered agent 'lp_solver'\n",
            "2025-11-07 15:55:27,061 | INFO | Registered agent 'fol_solver'\n",
            "2025-11-07 15:55:27,062 | INFO | Registered agent 'csp_solver'\n",
            "2025-11-07 15:55:27,062 | INFO | Registered agent 'smt_solver'\n",
            "2025-11-07 15:55:27,063 | INFO | Registered agent 'ilp_solver'\n",
            "2025-11-07 15:55:27,063 | INFO | Registered agent 'epistemic_solver'\n",
            "2025-11-07 15:55:27,063 | INFO | Registered agent 'risk_solver'\n",
            "2025-11-07 15:55:27,064 | INFO | Registered agent 'compositional_solver'\n",
            "2025-11-07 15:55:27,064 | INFO | Registered agent 'causal_solver'\n",
            "2025-11-07 15:55:32,303 | INFO | HTTP Request: POST https://lunarchatgpt.openai.azure.com/openai/deployments/lunar-chatgpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "2025-11-07 15:55:32,307 | INFO | Scratchpad WRITE problem_type_ques_1=SAT (ttl=None)\n",
            "2025-11-07 15:55:32,307 | INFO | Scratchpad WRITE trial_description_ques_1=PATIENT CASE FOR TRIAL MATCHING: Patient Profile: - 62-year- (ttl=None)\n",
            "2025-11-07 15:55:32,307 | INFO | Scratchpad WRITE sample_description_ques_1=Clinical Trial: NCT02142751 Trial Criteria: Inclusion: - ‚â•18 (ttl=None)\n",
            "2025-11-07 15:55:32,308 | INFO | Scratchpad WRITE options_ques_1=A) Yes\n",
            "B) No (ttl=None)\n",
            "2025-11-07 15:55:32,308 | INFO | Scratchpad WRITE smt_input_ques_1={'problem': \"Trial: PATIENT CASE FOR TRIAL MATCHING: Patient (ttl=None)\n",
            "2025-11-07 15:55:32,308 | INFO | Scratchpad WRITE description_ques_1=For a Boolean Satisfiability (SAT) problem, verify whether a (ttl=None)\n",
            "2025-11-07 15:55:32,309 | INFO | Scratchpad WRITE problem_type_ques_2=LP (ttl=None)\n",
            "2025-11-07 15:55:32,309 | INFO | Scratchpad WRITE premise_ques_2=HOSPITAL CREDENTIALING VERIFICATION: Excerpt from Hospital P (ttl=None)\n",
            "2025-11-07 15:55:32,309 | INFO | Scratchpad WRITE hypothesis_ques_2=Nurse Johnson is currently credentialed. (ttl=None)\n",
            "2025-11-07 15:55:32,310 | INFO | Scratchpad WRITE options_ques_2=A) Yes\n",
            "B) No (ttl=None)\n",
            "2025-11-07 15:55:32,310 | INFO | Scratchpad WRITE description_ques_2=For a Logic Programming (LP) problem, determine whether a hy (ttl=None)\n",
            "2025-11-07 15:55:32,310 | INFO | Scratchpad WRITE problem_type_ques_3=LP (ttl=None)\n",
            "2025-11-07 15:55:32,311 | INFO | Scratchpad WRITE premise_ques_3=DISCHARGE READINESS VERIFICATION: Patient Discharge Protocol (ttl=None)\n",
            "2025-11-07 15:55:32,311 | INFO | Scratchpad WRITE hypothesis_ques_3=Margaret Chen is cleared for discharge. (ttl=None)\n",
            "2025-11-07 15:55:32,311 | INFO | Scratchpad WRITE options_ques_3=A) Yes\n",
            "B) No (ttl=None)\n",
            "2025-11-07 15:55:32,312 | INFO | Scratchpad WRITE description_ques_3=For a Logic Programming (LP) problem, determine whether a hy (ttl=None)\n",
            "2025-11-07 15:55:32,312 | INFO | Scratchpad WRITE GOAL=Solve multiple independent reasoning problems (ttl=None)\n",
            "2025-11-07 15:55:32,312 | INFO | Scratchpad WRITE parsing_result=[{'problem_id': 'ques_1', 'problem_type': 'SAT', 'trial_desc (ttl=None)\n",
            "2025-11-07 15:55:32,313 | INFO | Scratchpad WRITE portfolio={'<PLAN_START>': {'goal': 'Special control marker, indicatin (ttl=None)\n",
            "2025-11-07 15:55:33,319 | INFO | HTTP Request: POST https://lunarchatgpt.openai.azure.com/openai/deployments/lunar-chatgpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "2025-11-07 15:55:33,321 | INFO | [planner] produced plan spec: {'agents': ['ques_1', 'ques_2', 'ques_3', 'smt_solver', 'lp_solver', '<PLAN_END>'], 'edges': [['ques_1', 'smt_solver'], ['smt_solver', '<PLAN_END>'], ['ques_2', 'lp_solver'], ['lp_solver', '<PLAN_END>'], ['ques_3', 'lp_solver'], ['lp_solver', '<PLAN_END>']]}\n"
          ]
        }
      ],
      "source": [
        "router = Planner(generator=llm)\n",
        "plans, memory, problem_ids = router({\"problem\": problem_description})\n",
        "plan = plans[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Let CARNAP Solve It\n",
        "\n",
        "We can now execute the plan!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-07 15:55:45,604 | INFO | Execute plan with topological order...\n",
            "2025-11-07 15:55:45,605 | INFO | Trace saved: <PLAN_START> ‚Üí None\n",
            "2025-11-07 15:55:45,605 | INFO | Trace saved: ques_3 ‚Üí None\n",
            "2025-11-07 15:55:45,605 | INFO | Trace saved: ques_2 ‚Üí None\n",
            "2025-11-07 15:55:45,606 | INFO | Trace saved: ques_1 ‚Üí None\n",
            "2025-11-07 15:55:47,875 | INFO | HTTP Request: POST https://lunarchatgpt.openai.azure.com/openai/deployments/lunar-chatgpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "2025-11-07 15:55:47,879 | INFO | Scratchpad WRITE intermediate_form_lp_solver=Predicates:\n",
            "classified($x, $type) ::: Is staff member $x cla (ttl=None)\n",
            "2025-11-07 15:55:47,880 | INFO | Attempt 1/1\n",
            "writing [compiled_krb]/facts.fbc\n",
            "writing [compiled_krb]/rules_fc.py\n",
            "writing [compiled_krb]/compiled_pyke_files.py\n",
            "2025-11-07 15:55:47,908 | INFO | Scratchpad WRITE critique_outputs_lp_solver=False (ttl=None)\n",
            "2025-11-07 15:55:47,909 | INFO | Pyke solver ran successfully.\n",
            "2025-11-07 15:55:48,397 | INFO | HTTP Request: POST https://lunarchatgpt.openai.azure.com/openai/deployments/lunar-chatgpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "2025-11-07 15:55:48,401 | INFO | Scratchpad WRITE solver_label_lp_solver=B (ttl=None)\n",
            "2025-11-07 15:55:48,401 | INFO | Scratchpad WRITE result_ques_2_ques_3={'ori_answer': 'False', 'parsed_answer': 'B', 'intermediate_ (ttl=None)\n",
            "2025-11-07 15:55:48,402 | INFO | Trace saved: lp_solver ‚Üí {'ori_answer': 'False', 'parsed_answer': 'B', 'intermediate_form': 'Predicates:\\nclassified($x, $type) ::: Is staff member $x classified as $type (clinical or administrative)?\\npatient_contact($x, bool) ::: Does staff member $x have direct patient contact?\\ninfection_training($x, bool) ::: Has staff member $x completed annual infection control training?\\ncredentialed($x, bool) ::: Is staff member $x credentialed?\\n\\nFacts:\\nclassified(Nurse_Johnson, clinical) ::: Nurses are classified as clinical staff.\\ninfection_training(Nurse_Johnson, False) ::: Nurse Johnson has not completed annual infection control training.\\ncredentialed(Nurse_Johnson, False) ::: Nurse Johnson is not credentialed.\\n\\nRules:\\nclassified($x, clinical) >>> patient_contact($x, True) ::: Clinical staff are defined as personnel who have direct patient contact in the course of their duties.\\ninfection_training($x, True) >>> credentialed($x, True) ::: Upon successful completion of annual infection control training, staff members receive credentialing authorization.\\nclassified(Nurse_Johnson, clinical) && infection_training(Nurse_Johnson, False) >>> credentialed(Nurse_Johnson, False) ::: All clinical staff are required to complete annual infection control training, and Nurse Johnson has not completed it, therefore she is not credentialed.\\n\\nQuery:\\ncredentialed(Nurse_Johnson, True) ::: Nurse Johnson is currently credentialed.', 'Rules': \"['classified($x, clinical) >>> patient_contact($x, True)', 'infection_training($x, True) >>> credentialed($x, True)', 'classified(Nurse_Johnson, clinical) && infection_training(Nurse_Johnson, False) >>> credentialed(Nurse_Johnson, False)']\", 'Facts': \"['classified(Nurse_Johnson, clinical)', 'infection_training(Nurse_Johnson, False)', 'credentialed(Nurse_Johnson, False)']\"}\n",
            "2025-11-07 15:55:48,402 | INFO | Scratchpad WRITE smt_problem_queue_smt_solver=[] (ttl=None)\n",
            "2025-11-07 15:55:56,131 | INFO | HTTP Request: POST https://lunarchatgpt.openai.azure.com/openai/deployments/lunar-chatgpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
            "2025-11-07 15:55:56,133 | INFO | Attempt 1/1\n",
            "2025-11-07 15:55:56,134 | INFO | Running Z3 command: z3 -smt2 /tmp/tmpszmpec4c.smt2\n",
            "2025-11-07 15:55:56,146 | INFO | Z3 ran successfully. Found 1 solutions\n",
            "2025-11-07 15:55:56,147 | INFO | Scratchpad WRITE smt_results_queue=[{'ori_answer': {}, 'parsed_answer': 'A', 'success': True, ' (ttl=None)\n",
            "2025-11-07 15:55:56,147 | INFO | Scratchpad WRITE result_ques_1={'ori_answer': {}, 'parsed_answer': 'A', 'success': True, 'e (ttl=None)\n",
            "2025-11-07 15:55:56,148 | INFO | Trace saved: smt_solver ‚Üí {'ori_answer': {}, 'parsed_answer': 'A', 'success': True, 'error': None, 'is_satisfiable': 'A', 'code': '; Declare variables and their types for Patient Profile\\n(declare-const age Int)\\n(declare-const is_male Bool)\\n(declare-const history_cva Bool)\\n(declare-const indwelling_catheter Bool)\\n(declare-const recent_urosepsis Bool)\\n(declare-const non_obstructing_stone Bool)\\n(declare-const urethral_strictures Bool)\\n(declare-const history_nhl Bool)\\n(declare-const history_bells_palsy Bool)\\n(declare-const history_bph Bool)\\n(declare-const history_hypertension Bool)\\n(declare-const history_bowel_obstruction Bool)\\n(declare-const history_hepatitis_c Bool)\\n(declare-const history_cryoglobulinemia Bool)\\n(declare-const history_sle Bool)\\n(declare-const history_diabetes Bool)\\n(declare-const history_esophagitis Bool)\\n(declare-const history_recurrent_utis Bool)\\n\\n; Declare variables and their types for Trial Criteria\\n(declare-const age_requirement Bool)\\n(declare-const mdri_ecoli_criteria Bool)\\n(declare-const urinary_sepsis_criteria Bool)\\n(declare-const poly_bacteremia Bool)\\n(declare-const unresolved_uropathy Bool)\\n(declare-const hematogenous_infection Bool)\\n(declare-const renal_transplant Bool)\\n(declare-const pregnant_or_breastfeeding Bool)\\n(declare-const hypersensitivity_criteria Bool)\\n\\n; Define eligibility requirement based on inclusion and exclusion\\n(define-fun inclusion_eligible () Bool\\n  (and age_requirement\\n       mdri_ecoli_criteria\\n       urinary_sepsis_criteria))\\n\\n(define-fun exclusion_criteria () Bool\\n  (or poly_bacteremia\\n      unresolved_uropathy\\n      hematogenous_infection\\n      renal_transplant\\n      pregnant_or_breastfeeding\\n      hypersensitivity_criteria))\\n\\n; Assert patient data\\n(assert (= age 62))\\n(assert (= is_male true))\\n(assert (= history_cva true))\\n(assert (= indwelling_catheter true))\\n(assert (= recent_urosepsis true))\\n(assert (= non_obstructing_stone true))\\n(assert (= urethral_strictures false))\\n(assert (= history_nhl true))\\n(assert (= history_bells_palsy true))\\n(assert (= history_bph true))\\n(assert (= history_hypertension true))\\n(assert (= history_bowel_obstruction true))\\n(assert (= history_hepatitis_c true))\\n(assert (= history_cryoglobulinemia true))\\n(assert (= history_sle true))\\n(assert (= history_diabetes true))\\n(assert (= history_esophagitis true))\\n(assert (= history_recurrent_utis true))\\n\\n; Assert trial inclusion criteria\\n(assert (= age_requirement (>= age 18)))\\n(assert (= mdri_ecoli_criteria true)) ; Assume true for simplification\\n(assert (= urinary_sepsis_criteria true)) ; Assume true based on symptoms and criteria\\n\\n; Assert trial exclusion criteria\\n(assert (= poly_bacteremia false))\\n(assert (= unresolved_uropathy false))\\n(assert (= hematogenous_infection false))\\n(assert (= renal_transplant false))\\n(assert (= pregnant_or_breastfeeding false))\\n(assert (= hypersensitivity_criteria false))\\n\\n; Assert trial eligibility by accommodation of both inclusion and non-exclusion\\n(assert (and inclusion_eligible\\n             (not exclusion_criteria)))\\n\\n; Check satisfiability\\n(check-sat)'}\n",
            "2025-11-07 15:55:56,148 | INFO | Trace saved: <PLAN_END> ‚Üí None\n",
            "2025-11-07 15:55:56,148 | INFO | Topological execution complete\n"
          ]
        }
      ],
      "source": [
        "trace_logger = TracePersister()\n",
        "plan.execute(memory, trace_logger)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Collecting results from memory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', None, None]\n"
          ]
        }
      ],
      "source": [
        "predictions = []\n",
        "for pid in problem_ids:\n",
        "    result = memory.read(f\"result_{pid}\") or {}\n",
        "    predictions.append(result.get('parsed_answer', None))\n",
        "\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The three predictions correspond to our three tasks, where **A = Yes** and **B = No**. For example, ['A', 'B', 'A']\n",
        " means:\n",
        "\n",
        "1. **Clinical Trial Matching:** A ‚Üí Patient **can** be enrolled\n",
        "2. **Policy Compliance:** B ‚Üí Nurse Johnson is **not** credentialed\n",
        "3. **Discharge Readiness:** A ‚Üí Margaret Chen is **cleared** for discharge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate \"Why\" HTML\n",
        "Package the execution trace and send it to the `why()` helper to refresh `demo_hospital_admin.html`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Captured 7 trace events for 3 tasks.\n"
          ]
        }
      ],
      "source": [
        "result_summary = []\n",
        "for pid in problem_ids:\n",
        "    result = memory.read(f\"result_{pid}\") or {}\n",
        "    result_summary.append({\n",
        "        \"problem_id\": pid,\n",
        "        \"parsed_answer\": result.get(\"parsed_answer\"),\n",
        "        \"raw_solver_output\": result.get(\"ori_answer\"),\n",
        "        \"solver_name\": result.get(\"solver_name\"),\n",
        "    })\n",
        "\n",
        "trace_payload = build_trace_payload(\n",
        "    plan,\n",
        "    trace_logger,\n",
        "    memory=memory,\n",
        "    metadata={\n",
        "        \"scenario\": \"Hospital admin assistant\",\n",
        "        \"problem_ids\": problem_ids,\n",
        "        \"result_summary\": result_summary,\n",
        "    },\n",
        "    problem_statement=problem_description,\n",
        ")\n",
        "print(f\"Captured {len(trace_payload['trace'])} trace events for {len(problem_ids)} tasks.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-07 15:56:45,068 | INFO | HTTP Request: POST https://lunarchatgpt.openai.azure.com/openai/deployments/lunar-chatgpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-11-07 15:56:45,070 | INFO | Retrying request to /chat/completions in 60.000000 seconds\n",
            "2025-11-07 15:57:45,653 | INFO | HTTP Request: POST https://lunarchatgpt.openai.azure.com/openai/deployments/lunar-chatgpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-11-07 15:57:45,654 | INFO | Retrying request to /chat/completions in 60.000000 seconds\n",
            "2025-11-07 15:58:46,242 | INFO | HTTP Request: POST https://lunarchatgpt.openai.azure.com/openai/deployments/lunar-chatgpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-11-07 15:58:46,243 | INFO | Error: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Your requests to lunar-chatgpt-4o for gpt-4o in East US have exceeded the token rate limit for your current OpenAI S0 pricing tier. This request was for ChatCompletions_Create under Azure OpenAI API version 2024-02-01. Please retry after 60 seconds. To increase your default rate limit, visit: https://aka.ms/oai/quotaincrease.'}}\n",
            "2025-11-07 15:58:46,244 | INFO | \n",
            "You are an expert neuro-symbolic reasoning communicator who converts solver traces into concise, visually rich HTML explanations. Your job is to help analysts understand *how* the solver reached its conclusions, while keeping formal guarantees and LLM interpretations clearly separated.\n",
            "\n",
            "Rendering requirements:\n",
            "- Produce a full self-contained HTML document with inline CSS (no external dependencies except Google Fonts).\n",
            "- Highlight the final answer and solver confidence near the top.\n",
            "- Break down the explanation into cards/sections (Scenario Overview, Plan & Agents, Code/Trace Highlights, Step-by-step reasoning, Interpretation & Warnings).\n",
            "- When you infer intent beyond the raw trace, prefix that sentence with ‚ÄúInterpretation:‚Äù so users know it is speculative.\n",
            "- If the trace contains code snippets, show the important ones in syntax-highlighted blocks and explain what each block enforces.\n",
            "- Mention the engine/solver names when available.\n",
            "- Encourage trust by stressing that code execution is formally guaranteed, but clearly warn that interpretive additions may contain mistakes.\n",
            "- Use a modern dark theme similar to the other demo HTML files (Inter font, rounded cards, gentle gradients, chips/pills for metadata).\n",
            "- Include subtle diagrammatic hints (simple SVG flow or timeline) if the trace structure allows it.\n",
            "- Close with a footer reminding readers that the HTML was generated from the trace on-demand.\n",
            "2025-11-07 15:58:51,794 | INFO | HTTP Request: POST https://lunarchatgpt.openai.azure.com/openai/deployments/lunar-chatgpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-11-07 15:58:51,795 | INFO | Retrying request to /chat/completions in 60.000000 seconds\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/openai/_base_client.py:1027\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[31mHTTPStatusError\u001b[39m: Client error '429 Too Many Requests' for url 'https://lunarchatgpt.openai.azure.com/openai/deployments/lunar-chatgpt-4o/chat/completions?api-version=2024-02-01'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     16\u001b[39m style_hint = (\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mHighlight the DAG, show per-task outcomes (A/B) as chips, and emphasise why each solver decision is trustworthy.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m extra_guidance = (\n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mName each task explicitly using the provided task_titles mapping and echo the answer summary: \u001b[39m\u001b[33m\"\u001b[39m + (answer_summary \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mpending answers.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m html = \u001b[43mwhy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrace_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnarrative_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnarrative_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstyle_hint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstyle_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_guidance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_guidance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdemo_hospital_admin.html\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3000\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m HTML(html)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/idiap.svm/temp.rea01/lxu/251009_Carnap_clean/workshop_release/adaptive_symbolic_reasoning/helpers/trace_explainer.py:105\u001b[39m, in \u001b[36mwhy\u001b[39m\u001b[34m(generator, trace_payload, narrative_context, style_hint, extra_guidance, output_path, prompt_name, prompt_dir, model_args)\u001b[39m\n\u001b[32m     98\u001b[39m replacements = {\n\u001b[32m     99\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnarrative_context\u001b[39m\u001b[33m\"\u001b[39m: narrative_context.strip(),\n\u001b[32m    100\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtrace\u001b[39m\u001b[33m\"\u001b[39m: json.dumps(trace_payload, indent=\u001b[32m2\u001b[39m),\n\u001b[32m    101\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstyle_hint\u001b[39m\u001b[33m\"\u001b[39m: (style_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip(),\n\u001b[32m    102\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mextra_guidance\u001b[39m\u001b[33m\"\u001b[39m: (extra_guidance \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip(),\n\u001b[32m    103\u001b[39m }\n\u001b[32m    104\u001b[39m final_model_args = model_args \u001b[38;5;129;01mor\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.2\u001b[39m}\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m html = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_prompt_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinal_model_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mreplacements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_path:\n\u001b[32m    112\u001b[39m     Path(output_path).write_text(html, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/idiap.svm/temp.rea01/lxu/251009_Carnap_clean/workshop_release/adaptive_symbolic_reasoning/agents/generation/api.py:250\u001b[39m, in \u001b[36mAzureOpenAIGenerator.generate\u001b[39m\u001b[34m(self, model_prompt_dir, prompt_name, prefix, numbered_list, remove_number, test, model_args, **replacements)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    248\u001b[39m     \u001b[38;5;66;03m# For Azure, use the existing parameter backup/restore system\u001b[39;00m\n\u001b[32m    249\u001b[39m     old_param_backup = \u001b[38;5;28mself\u001b[39m.set_model_args(model_args)\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompletion_with_backoff\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m            \u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m            \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m     \u001b[38;5;66;03m# Restore the model configuration\u001b[39;00m\n\u001b[32m    257\u001b[39m     _ = \u001b[38;5;28mself\u001b[39m.set_model_args(old_param_backup)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/remote/idiap.svm/temp.rea01/lxu/251009_Carnap_clean/workshop_release/adaptive_symbolic_reasoning/agents/generation/api.py:203\u001b[39m, in \u001b[36mAzureOpenAIGenerator.completion_with_backoff\u001b[39m\u001b[34m(self, messages, model_args)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;129m@tenacity\u001b[39m.retry(wait=tenacity.wait_fixed(\u001b[32m5\u001b[39m))\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompletion_with_backoff\u001b[39m(\u001b[38;5;28mself\u001b[39m, messages, model_args=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    202\u001b[39m         \u001b[38;5;66;03m# Azure ChatOpenAI - use existing parameter backup/restore system\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    205\u001b[39m         log.info(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:193\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    192\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1317\u001b[39m, in \u001b[36mBaseChatModel.__call__\u001b[39m\u001b[34m(self, messages, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1291\u001b[39m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m0.1.7\u001b[39m\u001b[33m\"\u001b[39m, alternative=\u001b[33m\"\u001b[39m\u001b[33minvoke\u001b[39m\u001b[33m\"\u001b[39m, removal=\u001b[33m\"\u001b[39m\u001b[33m1.0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m   1293\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1297\u001b[39m     **kwargs: Any,\n\u001b[32m   1298\u001b[39m ) -> BaseMessage:\n\u001b[32m   1299\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model.\u001b[39;00m\n\u001b[32m   1300\u001b[39m \n\u001b[32m   1301\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1315\u001b[39m \n\u001b[32m   1316\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1317\u001b[39m     generation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1318\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1319\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m   1320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[32m   1321\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation.message\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:842\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    840\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    841\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m         )\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    850\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1091\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1089\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1095\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:973\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    971\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    972\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m973\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/openai/_base_client.py:1033\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1032\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sleep_for_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/idiap/temp/lxu/miniconda3/envs/carnap_test/lib/python3.11/site-packages/openai/_base_client.py:1073\u001b[39m, in \u001b[36mSyncAPIClient._sleep_for_retry\u001b[39m\u001b[34m(self, retries_taken, max_retries, options, response)\u001b[39m\n\u001b[32m   1070\u001b[39m timeout = \u001b[38;5;28mself\u001b[39m._calculate_retry_timeout(remaining_retries, options, response.headers \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1071\u001b[39m log.info(\u001b[33m\"\u001b[39m\u001b[33mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m, options.url, timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "task_titles = {\n",
        "    \"ques_1\": \"Clinical Trial Enrollment\",\n",
        "    \"ques_2\": \"Credential Compliance\",\n",
        "    \"ques_3\": \"Discharge Clearance\",\n",
        "}\n",
        "answer_summary = \", \".join(\n",
        "    f\"{task_titles.get(item['problem_id'], item['problem_id'])}: {item.get('parsed_answer')}\"\n",
        "    for item in result_summary\n",
        "    if item.get('parsed_answer')\n",
        ")\n",
        "narrative_context = (\n",
        "    \"Carnap routed three hospital-admin subtasks (trial matching, credentialing, discharge) through the symbolic plan.\"\n",
        ")\n",
        "style_hint = (\n",
        "    \"Highlight the DAG, show per-task outcomes (A/B) as chips, and emphasise why each solver decision is trustworthy.\"\n",
        ")\n",
        "extra_guidance = (\n",
        "    \"Name each task explicitly using the provided task_titles mapping and echo the answer summary: \" + (answer_summary or \"pending answers.\")\n",
        ")\n",
        "html = why(\n",
        "    llm,\n",
        "    trace_payload,\n",
        "    narrative_context=narrative_context,\n",
        "    style_hint=style_hint,\n",
        "    extra_guidance=extra_guidance,\n",
        "    output_path=\"demo_hospital_admin.html\",\n",
        "    model_args={\"temperature\": 0.15, \"max_tokens\": 3000},\n",
        ")\n",
        "HTML(html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "carnap_test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
